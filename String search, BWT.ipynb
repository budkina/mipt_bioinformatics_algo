{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01dd7016",
   "metadata": {},
   "source": [
    "# String-searching algorithms\n",
    "\n",
    "String-searching algorithms find positions where one or several strings (also called patterns) are found within a larger string.\n",
    "\n",
    "We search pattern $P$: $p_1p_2 . . . p_m$ of length $m$ in a template string $T$: $t_1t_2 . . . t_n$ of length $n$.\n",
    "\n",
    "Output:\n",
    "\n",
    "Position i of a substring $T[i:j] = P$\n",
    "\n",
    "## Naive approach\n",
    "\n",
    "We move along the string T character by character, checking for a match with P at each position.\n",
    "\n",
    "Time complexity in the worst case: $O(mn)$\n",
    "\n",
    "![Title](img/naive_string_search.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8209ca5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match at position 0\n",
      "Match at position 1\n",
      "Match at position 5\n",
      "Match at position 6\n"
     ]
    }
   ],
   "source": [
    "def naive_search(t, p):\n",
    "    m = len(p)\n",
    "    n = len(t)\n",
    "    i = 0\n",
    "    while i <= n - m:\n",
    "        j = 0\n",
    "        while j < n:\n",
    "            if p[j] != t[i+j]:\n",
    "                break\n",
    "            else:\n",
    "                j += 1\n",
    "            if j == m:\n",
    "                print(f\"Match at position {i}\")\n",
    "                break\n",
    "        i+=1\n",
    "        \n",
    "naive_search(\"aaaabaaaa\", \"aaa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf342338",
   "metadata": {},
   "source": [
    "## Boyer-Moore Algorithm\n",
    "\n",
    "The main idea of the Boyer-Moore algorithm is to skip unnecessary alignments during search.\n",
    "\n",
    "Alignment direction - left-to-right\n",
    "\n",
    "Comparison direction - right-to-left\n",
    "\n",
    "![Title](img/boyer-moore.png)\n",
    "\n",
    "Every time we calculate how many positions in the T string we can skip during a search, we proceed from two rules: the bad character rule and the good suffix rule.\n",
    "\n",
    "### Bad character rule\n",
    "\n",
    "Upon mismatch, skip alignments until\n",
    "\n",
    "I. A mismatch becomes a match.\n",
    "\n",
    "or\n",
    "\n",
    "II. P moves past a mismatched character.\n",
    "\n",
    "![Title](img/boyer-moore_bad_char.png)\n",
    "\n",
    "We can precalculate the number of alignments we can skip:\n",
    "\n",
    "![Title](img/boyer-moore_bad_char_precalc.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d24ece5",
   "metadata": {},
   "source": [
    "## Good suffix rule\n",
    "\n",
    "Let's define the string $s$ as a substring of T that matches a suffix of $P$  at a given position. We can skip alignments until\n",
    "\n",
    "I. There are no mismatches between P and s.\n",
    "\n",
    "or\n",
    "\n",
    "II. P moves past s until the prefix of P matches the suffix of s.\n",
    "\n",
    "![Title](img/boyer-moore_good_suf.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74a94a7",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "\n",
    "https://github.com/jordancheah/DNA-Sequencing-Boyer-Moore-Approximate-Matching/blob/master/boyermoore.py\n",
    "\n",
    "Time complexity in the worst-case: $O(mn)$\n",
    "\n",
    "Time complexity in the best-case: $O(n/m)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aeccf79",
   "metadata": {},
   "source": [
    "# Knuth-Morris-Pratt Algorithm\n",
    "\n",
    "**Prefix function** of string $S$:\n",
    "\n",
    "$PrefixFunction(S)$ = max length $n$ ($n < |S|$) of prefix $S[: n]$ that equals to the suffix $S[−n :]$.\n",
    "\n",
    "Example:\n",
    "\n",
    "PrefixFunction(**abra**cad**abra**) = 4\n",
    "\n",
    "**abra** is the prefix and suffix. We can calculate PrefixFunction for all prefixes in the template string $T$:\n",
    "\n",
    "![Title](img/prefix_function.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a9d2412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 1, 0, 1, 0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prefix_function(s):\n",
    "    n =  len(s)\n",
    "    prefix_array = [0]*n\n",
    "    for i in range(1,n):\n",
    "        j = prefix_array[i-1]\n",
    "        while j > 0 and s[i] != s[j]:\n",
    "            j = prefix_array[j-1]\n",
    "        if s[i] == s[j]:\n",
    "            j+=1\n",
    "        prefix_array[i] = j\n",
    "    return prefix_array\n",
    "\n",
    "prefix_function('abracadabra')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f8b2fd",
   "metadata": {},
   "source": [
    "### Knuth-Morris-Pratt algorithm steps:\n",
    "\n",
    "- Concatenate strings P and T using some separator character, e.g., \\$\n",
    "\n",
    "- Calculate PrefixFunction(P\\$T)\n",
    "\n",
    "- Using the PrefixFunction array, find prefixes U: PrefixFunction(U) = Length(P)\n",
    "\n",
    "Example: T = banana, P = ana\n",
    "\n",
    "![Title](img/knuth_morris_pratt.png)\n",
    "\n",
    "Time complexity: $T = O(m+n)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77fa419f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'kmp1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_35732\\2420031451.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefix_array\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mkmp1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'banana'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ana'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'kmp1' is not defined"
     ]
    }
   ],
   "source": [
    "def kmp(t,p):\n",
    "    prefix_array = prefix_function(p+\"$\"+t)\n",
    "    return [i - len(t) for i, x in enumerate(prefix_array) if x == len(p)]\n",
    "\n",
    "kmp1('banana', 'ana')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee2c237",
   "metadata": {},
   "source": [
    "# Rabin-Karp Algorithm\n",
    "\n",
    "The main idea of the algorithm is to calculate the hash function of each substring of T and compare the hash values with the hash of the pattern P.\n",
    "\n",
    "String T: $s_1s_2...s_n$ each character has its own number representation: $\\sigma_1\\sigma_2...\\sigma_n$.\n",
    "\n",
    "Hash function of a string polynom:\n",
    "\n",
    "$N(S) = \\sigma_1A^{n-1} + \\sigma_2A^{n-2} + ... + \\sigma_n$\n",
    "\n",
    "String hash $H(i) = N(i) mod M$, where $A$ and $M$ are coprime.\n",
    "\n",
    "\n",
    "###  Rolling hash\n",
    "\n",
    "When shifted one position in a string T, the hash function from the new substring can be calculated using the value of the hash function at the previous position using a **rolling hash**.\n",
    "\n",
    "![Title](img/rolling_hash.png)\n",
    "\n",
    "$H(T[i:i+m]) = \\sigma_i\\cdot A^m + H(T[i+1:i+m])$\n",
    "\n",
    "$H(T[i+1:i+m]) = H(T[i:i+m]) -  \\sigma_i\\cdot A^m$\n",
    "\n",
    "$H(T[i+1:i+m+1]) = A\\cdot(H(T[i:i+m]) -  \\sigma_i\\cdot A^m) + \\sigma_{i+m+1}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf8cf91",
   "metadata": {},
   "source": [
    "\n",
    "### Rabin-Karp algorithm steps: \n",
    "\n",
    "1) Compute $H(P)$.\n",
    "\n",
    "2) Compute a hash function for each substring of $T$ of length $m$: $H(T[i: i + m]) $.\n",
    "\n",
    "3) If $H(T[i: i + m]) = H(P)$, compare strings character by character to avoid collisions.\n",
    "\n",
    "Worst-case time complexity (n-m matches found): $O(m(n-m))$\n",
    "\n",
    "Best-case time complexity (no matches found): $O(n + m)$\n",
    "\n",
    "Time complexity for k matches: $O(n + m + km)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fce33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RabinKarp:\n",
    "    def __init__(self):\n",
    "        self.A = 256\n",
    "        self.M = 101\n",
    "    \n",
    "    def hash(self, s):\n",
    "        h = 0\n",
    "        for c in s:\n",
    "            h = (h * self.A + ord(c)) % self.M\n",
    "        return h\n",
    "    \n",
    "    def search(self, t, p):\n",
    "        n = len(t)\n",
    "        m = len(p)\n",
    "        hash_p = self.hash(p)\n",
    "        h = pow(self.A, m-1, self.M)\n",
    "        hash_t = self.hash(t[:m])\n",
    "        results = []\n",
    "        \n",
    "        for i in range(n-m+1):\n",
    "            if hash_t == hash_p:\n",
    "                match = True\n",
    "                for j in range(m):\n",
    "                    if t[i+j] != p[j]:\n",
    "                        match = False\n",
    "                        break\n",
    "                if match:\n",
    "                    results.append(i)\n",
    "            \n",
    "            if i < n-m:\n",
    "                hash_t = (self.A*(hash_t - ord(t[i])*h) + ord(t[i+m])) % self.M\n",
    "        \n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1ade08",
   "metadata": {},
   "outputs": [],
   "source": [
    "rabin_karp = RabinKarp()\n",
    "rabin_karp.search('CAGCAGCGCAG', 'CAG')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24169b8a",
   "metadata": {},
   "source": [
    "# Aho–Corasick algorithm\n",
    "\n",
    "The Aho-Corasick algorithm can be used to simultaneously search for several patterns in text. The algorithm uses a trie structure.\n",
    "\n",
    "\n",
    "Input:\n",
    "\n",
    "T - template string\n",
    "\n",
    "k pattern strings: $P_1$,...,$Pk$\n",
    "\n",
    "Output:\n",
    "\n",
    "All occurrences of $P_1$,...,$Pk$ in T.\n",
    "\n",
    "### Trie\n",
    "\n",
    "A trie is a tree-like data structure that is used to efficiently store and retrieve strings or sequences of characters. Each edge of such a tree is labeled with a character. The nodes are empty or can contain the marker of the end of the string.\n",
    "\n",
    "Example:\n",
    "\n",
    "The words he, she, his, and hers were added to the trie:\n",
    "\n",
    "![Title](https://neerc.ifmo.ru/wiki/images/e/ea/%D0%91%D0%BE%D1%80.jpg)\n",
    "\n",
    "Adding a string: $O(n)$\n",
    "\n",
    "Retrieving a string: $O(n)$\n",
    "\n",
    "### Suffix links\n",
    "\n",
    "To implement the Aho-Corasick algorithm, we add all pattern strings $P_1$,...,$Pk$ to a trie. Next, we add suffix links to the trie.\n",
    "\n",
    "**Suffix link**: $\\pi(u)=v$, if $v$ is a maximum length suffix of $u$ present in the trie, $v \\neq u$. If no such node can be found, we set a suffix link from the current node to the root.\n",
    "\n",
    "![Title](https://neerc.ifmo.ru/wiki/images/d/d6/Axo.jpg)\n",
    "\n",
    "### Aho–Corasick algorithm steps\n",
    "\n",
    "1) Build a trie with suffix links from $P_1$,...,$Pk$.\n",
    "\n",
    "2) Process characters from T one by one and follow the links in the trie at each step.\n",
    "\n",
    "\n",
    "The algorithm constructs a finite-state machine. Suffix links allow fast transitions between failed string matches to other branches of the trie that share a common prefix.\n",
    "\n",
    "Example:\n",
    "\n",
    "T: shers\n",
    "\n",
    "Path for search :\n",
    "\n",
    "→ s → h → e → suffixlink → r → s\n",
    "\n",
    "Functions:\n",
    "\n",
    "- **goto** function returns a state that can be reached from state s by character a\n",
    "\n",
    "- **fail** function returns the state to go by non-matching character (by suffix link).\n",
    "\n",
    "- **out** function returns a set of patterns, occurrences of which are detected upon transition to state s\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84faca2",
   "metadata": {},
   "source": [
    "# Suffix Array\n",
    "\n",
    "A suffix array is a sorted array of all suffixes in a string that includes the position of each suffix in the template string. \n",
    "To find a pattern in a string, we can find all the suffixes in the array that have the pattern we are looking for as a prefix. Binary search can be used.\n",
    "\n",
    "![Title](img/suffix_array.png)\n",
    "\n",
    "https://github.com/dohlee/pysuffixarray/blob/master/pysuffixarray/core.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cbb526",
   "metadata": {},
   "source": [
    "# Suffix tree\n",
    "\n",
    "First, let's build trie using suffix strings from the suffix array.\n",
    "\n",
    "![Title](img/suffix_trie.png)\n",
    "\n",
    "We can compress the suffix trie into the suffix tree to reduce the amount of memory used. Ukkonen's algorithm can be used to construct a suffix tree in linear time.\n",
    "\n",
    "![Title](img/suffix_tree.png)\n",
    "\n",
    "To check the occurrence of a pattern, we can go along the corresponding edges in the trie. To get all the positions of its occurrence, we must get the positions of the suffixes from the leaf vertices accessible from a given node.\n",
    "\n",
    "![Title](img/suffix_trie_search.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a34f488",
   "metadata": {},
   "source": [
    "About MUMmer: https://www.biostat.wisc.edu/bmi776/spring-18/lectures/long-alignment.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bce2b59",
   "metadata": {},
   "source": [
    "# Burrows-Wheeler Transform\n",
    "\n",
    "S = ABAABA\\$\n",
    "\n",
    "1. Get all rotations of the string:\n",
    "\n",
    "![Title](img/bwt_rotations.png)\n",
    "\n",
    "**BWT(S) = ABBA\\$AA**\n",
    "\n",
    "We can compress the BWT result using run-length encoding (RLE):\n",
    "\n",
    "**1A2B1\\$2A**\n",
    "\n",
    "![Title](img/bwt_lf.png)\n",
    "\n",
    "## BWT: reversing\n",
    "\n",
    "Starting from \\$.\n",
    "\n",
    "![Title](img/bwt_reversing.png)\n",
    "\n",
    "\n",
    "## BWT: pattern search\n",
    "\n",
    "![Title](img/bwt_search.png)\n",
    "\n",
    "### BWT lection: \n",
    "\n",
    "https://www.youtube.com/watch?v=6BJbEWyO_N0\n",
    "\n",
    "https://www.youtube.com/watch?v=GWFb_C4IR14\n",
    "\n",
    "### BWT implementation:\n",
    "\n",
    "https://github.com/BenLangmead/comp-genomics-class/tree/master/notebooks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
